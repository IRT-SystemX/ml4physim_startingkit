{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to show  examples of functionnal submission packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General submission process\n",
    "\n",
    "All submissions are processed by the codabench plateform. In order to submit a model for the competition, the submission folder need to be compressed as a zip file (be carefull to compress all the files and not the folder itself, the unzipping need to recreate the file and not a folder containing the files). This zip can then be uploaded on the `my_submission` tab :\n",
    "\n",
    "![Alt text](utils/img/submission.png)\n",
    "\n",
    "Once submitted it is processed by the codabench plateform and send to one of our compute node for evaluation. It is possible to see the current status of the submission (submitted, waiting for worker, running, done) however the logs will only be available once the submission is done running. \n",
    "\n",
    "Please note that we currently have a 12hours limit for the execution of a submission (training, evaluation and scoring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 : simple submission\n",
    "\n",
    "This example is available in submission/simple \n",
    "\n",
    "It correspond to a simple submission that use pre-implemented model and scaler and recreate the 1st example from the 4th notebook.\n",
    "This submission is composed of 3 files :\n",
    "- parameters.json\n",
    "- config.ini\n",
    "- scaler_parameters.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### parameters.json\n",
    "\n",
    "\n",
    "In this example we are using a fully connected model implemented through torch and already available in the LIPS package :\n",
    "- `from lips.augmented_simulators.torch_models.fully_connected import TorchFullyConnected`\n",
    "\n",
    "We also want to train and evaluate the model as such we indicate \n",
    "- `evaluateonly: false`\n",
    "- `scoringonly\": false`\n",
    "\n",
    "#### simulator_config :\n",
    "As we are use an already implemented simulator/model we use :\n",
    "- `custom_simulator : false` \n",
    "Which indicate to the compute node that it will need to load the model from the LIPS package\n",
    "We name the model (used for saving an retrieving models, not important in this type of submission):\n",
    "- `name: \"MyAugmentedSimulator\"`\n",
    "And indicates to the compute node which model class and implementation we are using :\n",
    "- `model_type: \"fully_connected\"`\n",
    "- `model: \"TorchFullyConnected\"`\n",
    "\n",
    "This will load the following model when running :  `from lips.augmented_simulators.torch_models.fully_connected import TorchFullyConnected`\n",
    "\n",
    "In this example we also use a pre-implemented scaler : `from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative`\n",
    "Similarly we indicate which scaler class and implementation to load :\n",
    "- `scaler_class: \"standard_scaler_iterative\"`\n",
    "- `scaler: \"StandardScalerIterative\"`\n",
    "\n",
    "We then indicate which configuration will need to be used from the config.ini file (in this example we use the standard config presented in the 1st example of notebook 4):\n",
    "- `config_name: \"DEFAULT\"`\n",
    "\n",
    "#### simulator_extra_parameters:\n",
    "This section is used to pass custom parameters to the model and generally will be only used in association with a custom model as presented in the following example.\n",
    "As we are running a pre-implemented model, we do not pass any custom parameters and `simulator_extra_parameters` stay empty :\n",
    "- `simulator_extra_parameters: {}`\n",
    "\n",
    "#### training_config:\n",
    "We now configure to run the training for 10 epochs :\n",
    "- `training_config: {\"epoch\": 10}`\n",
    "\n",
    "Architecture_type is not used for the submission process and stay at \"Classical\"\n",
    "\n",
    "The resulting `parameters.json` file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"evaluateonly\": false,\n",
    "  \"scoringonly\": false,\n",
    "  \"simulator_config\": {\n",
    "    \"custom_simulator\": false,\n",
    "    \"name\": \"MyAugmentedSimulator\",\n",
    "    \"model\": \"TorchFullyConnected\",\n",
    "    \"model_type\": \"fully_connected\",\n",
    "    \"custom_scaler\": false,\n",
    "    \"scaler_class\": \"standard_scaler_iterative\",\n",
    "    \"scaler\": \"StandardScalerIterative\",\n",
    "    \"config_name\": \"DEFAULT\",\n",
    "    \"architecture_type\": \"Classical\"\n",
    "  },\n",
    "  \"simulator_extra_parameters\": {},\n",
    "  \"training_config\": {\n",
    "    \"epochs\": 10\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config.ini\n",
    "This file is used to pass the configuration used in the model, as presented in notebook 4.\n",
    "We had the configuration file as defined in previous notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[DEFAULT]\n",
    "name = \"torch_fc\"\n",
    "layers = (64,64,8,64,64,64,8,64,64)\n",
    "activation = \"relu\"\n",
    "layer = \"linear\"\n",
    "input_dropout = 0.0\n",
    "dropout = 0.0\n",
    "metrics = (\"MAELoss\",)\n",
    "loss = {\"name\": \"MSELoss\",\n",
    "        \"params\": {\"size_average\": None,\n",
    "                   \"reduce\": None,\n",
    "                   \"reduction\": 'mean'}}\n",
    "device = \"cpu\"\n",
    "optimizer = {\"name\": \"adam\",\n",
    "             \"params\": {\"lr\": 2e-4}}\n",
    "train_batch_size = 128000\n",
    "eval_batch_size = 256000\n",
    "epochs = 200\n",
    "shuffle = False\n",
    "save_freq = False\n",
    "ckpt_freq = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaler_parameter.py\n",
    "\n",
    "This file contains the function that return the arguments for the scaler. The function take in argument the `benchmark` object (see notebook 4). In this example we use a standard iterative scaler implemented in LIPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function that return the parameters of the scaler\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "\n",
    "def compute_scaler_parameters(benchmark):\n",
    "    chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "    no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "    scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "    return scalerParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 : custom model\n",
    "\n",
    "This example is available in submission/custom_model\n",
    "\n",
    "It correspond to a submission that use a custom model implemented in `my_augmented_simulator.py` and a pre-implemented scaler. It recreates the 2nd example from the 4th notebook.\n",
    "This submission is composed of 4 files :\n",
    "- parameters.json\n",
    "- config.ini\n",
    "- scaler_parameters.py\n",
    "- my_augmented_simulator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters.json\n",
    "\n",
    "\n",
    "In this example we are using a custom model implemented in `my_augmented_simulator.py`.ed`\n",
    "\n",
    "We also want to train and evaluate the model as such we indicate \n",
    "- `evaluateonly: false`\n",
    "- `scoringonly\": false`\n",
    "\n",
    "#### simulator_config :\n",
    "As we are use an already implemented simulator/model we use :\n",
    "- `custom_simulator : true` \n",
    "Which indicate to the compute node that it will need to load the model from `my_augmented_simulator.py`\n",
    "We name the model (used for saving an retrieving models, not important in this type of submission):\n",
    "- `name: \"MyAugmentedSimulator\"`\n",
    "And indicates to the compute node which model we are using :\n",
    "- `model: \"MyCustomFullyConnected\"`\n",
    "This correspond to the name of the class implemented in `my_augmented_simulator.py`.\n",
    "\n",
    "In this example we also use a pre-implemented scaler : `from lips.dataset.scaler.standard_scaler_iterative import StandardScalerIterative`\n",
    "Similarly we indicate which scaler class and implementation to load :\n",
    "- `scaler_class: \"standard_scaler_iterative\"`\n",
    "- `scaler: \"StandardScalerIterative\"`\n",
    "\n",
    "We then indicate which configuration will need to be used from the config.ini file (in this example we use the standard config presented in the 1st example of notebook 4):\n",
    "- `config_name: \"DEFAULT\"`\n",
    "\n",
    "#### simulator_extra_parameters:\n",
    "This section is used to pass custom parameters to the model, it presents in the same form as training_config.\n",
    "In this case, we do not pass any custom parameters and `simulator_extra_parameters` stay empty :\n",
    "- `simulator_extra_parameters: {}`\n",
    "\n",
    "#### training_config:\n",
    "We now configure to run the training for 10 epochs :\n",
    "- `training_config: {\"epoch\": 10}`\n",
    "\n",
    "Architecture_type is not used for the submission process and stay at \"Classical\"\n",
    "\n",
    "The resulting `parameters.json` file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"evaluateonly\": false,\n",
    "  \"scoringonly\": false,\n",
    "  \"simulator_config\": {\n",
    "    \"custom_simulator\": true,\n",
    "    \"name\": \"MyAugmentedSimulator\",\n",
    "    \"model\": \"MyCustomFullyConnected\",\n",
    "    \"model_type\": \"my_augmented_simulator\",\n",
    "    \"custom_scaler\": false,\n",
    "    \"scaler_class\": \"standard_scaler_iterative\",\n",
    "    \"scaler\": \"StandardScalerIterative\",\n",
    "    \"config_name\": \"DEFAULT\",\n",
    "    \"architecture_type\": \"Classical\"\n",
    "  },\n",
    "  \"simulator_extra_parameters\": {},\n",
    "  \"training_config\": {\n",
    "    \"epochs\": 10\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config.ini\n",
    "This file is used to pass the configuration used in the model, as presented in notebook 4.\n",
    "We had the configuration file as defined in previous notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[DEFAULT]\n",
    "name = \"torch_fc\"\n",
    "layers = (64,64,8,64,64,64,8,64,64)\n",
    "activation = \"relu\"\n",
    "layer = \"linear\"\n",
    "input_dropout = 0.0\n",
    "dropout = 0.0\n",
    "metrics = (\"MAELoss\",)\n",
    "loss = {\"name\": \"MSELoss\",\n",
    "        \"params\": {\"size_average\": None,\n",
    "                   \"reduce\": None,\n",
    "                   \"reduction\": 'mean'}}\n",
    "device = \"cpu\"\n",
    "optimizer = {\"name\": \"adam\",\n",
    "             \"params\": {\"lr\": 2e-4}}\n",
    "train_batch_size = 128000\n",
    "eval_batch_size = 256000\n",
    "epochs = 200\n",
    "shuffle = False\n",
    "save_freq = False\n",
    "ckpt_freq = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaler_parameter.py\n",
    "\n",
    "This file contains the function that return the arguments for the scaler. The function take in argument the `benchmark` object (see notebook 4). In this example we use a standard iterative scaler implemented in LIPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function that return the parameters of the scaler\n",
    "from lips.benchmark.airfransBenchmark import AirfRANSBenchmark\n",
    "\n",
    "def compute_scaler_parameters(benchmark):\n",
    "    chunk_sizes=benchmark.train_dataset.get_simulations_sizes()\n",
    "    no_norm_x=benchmark.train_dataset.get_no_normalization_axis_indices()\n",
    "    scalerParams={\"chunk_sizes\":chunk_sizes,\"no_norm_x\":no_norm_x}\n",
    "    return scalerParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my_augmented_simulator.py\n",
    "\n",
    "This file contains the implementation of a custom model. This implementation needs to be compatible with the LIPS simulator class in order for the simulation and evaluation processes to be able to access it. Here we implement and example of a fully connected pytorch model as seen in the 2nd example of the 4th notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Torch fully connected model\n",
    "\"\"\"\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Union\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from lips.dataset import DataSet\n",
    "from lips.dataset.scaler import Scaler\n",
    "from lips.logger import CustomLogger\n",
    "from lips.config import ConfigManager\n",
    "from lips.utils import NpEncoder\n",
    "\n",
    "class MyCustomFullyConnected(nn.Module):\n",
    "    def __init__(self,\n",
    "                 sim_config_path: Union[pathlib.Path, str],\n",
    "                 bench_config_path: Union[str, pathlib.Path],\n",
    "                 sim_config_name: Union[str, None]=None,\n",
    "                 bench_config_name: Union[str, None]=None,\n",
    "                 name: Union[str, None]=None,\n",
    "                 scaler: Union[Scaler, None]=None,\n",
    "                 log_path: Union[None, pathlib.Path, str]=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if not os.path.exists(sim_config_path):\n",
    "            raise RuntimeError(\"Configuration path for the simulator not found!\")\n",
    "        if not str(sim_config_path).endswith(\".ini\"):\n",
    "            raise RuntimeError(\"The configuration file should have `.ini` extension!\")\n",
    "        # if test_custom_param:\n",
    "        #     print(\"test_custom_param: \", test_custom_param)\n",
    "        sim_config_name = sim_config_name if sim_config_name is not None else \"DEFAULT\"\n",
    "        self.sim_config = ConfigManager(section_name=sim_config_name, path=sim_config_path)\n",
    "        self.bench_config = ConfigManager(section_name=bench_config_name, path=bench_config_path)\n",
    "        self.name = name if name is not None else self.sim_config.get_option(\"name\")\n",
    "        # scaler\n",
    "        self.scaler = scaler\n",
    "        # Logger\n",
    "        self.log_path = log_path\n",
    "        self.logger = CustomLogger(__class__.__name__, log_path).logger\n",
    "        # model parameters\n",
    "        self.params = self.sim_config.get_options_dict()\n",
    "        self.params.update(kwargs)\n",
    "\n",
    "        self.activation = {\n",
    "            \"relu\": F.relu,\n",
    "            \"sigmoid\": F.sigmoid,\n",
    "            \"tanh\": F.tanh\n",
    "        }\n",
    "\n",
    "        self.input_size = None if kwargs.get(\"input_size\") is None else kwargs[\"input_size\"]\n",
    "        self.output_size = None if kwargs.get(\"output_size\") is None else kwargs[\"output_size\"]\n",
    "\n",
    "        self.input_layer = None\n",
    "        self.input_dropout = None\n",
    "        self.fc_layers = None\n",
    "        self.dropout_layers = None\n",
    "        self.output_layer = None\n",
    "\n",
    "        #self.__build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build the model architecture\n",
    "        \"\"\"\n",
    "        linear_sizes = list(self.params[\"layers\"])\n",
    "\n",
    "        self.input_layer = nn.Linear(self.input_size, linear_sizes[0])\n",
    "        self.input_dropout = nn.Dropout(p=self.params[\"input_dropout\"])\n",
    "\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(in_f, out_f) \\\n",
    "            for in_f, out_f in zip(linear_sizes[:-1], linear_sizes[1:])])\n",
    "\n",
    "        self.dropout_layers = nn.ModuleList([nn.Dropout(p=self.params[\"dropout\"]) \\\n",
    "            for _ in range(len(self.fc_layers))])\n",
    "\n",
    "        self.output_layer = nn.Linear(linear_sizes[-1], self.output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \"\"\"\n",
    "        out = self.input_layer(data)\n",
    "        out = self.input_dropout(out)\n",
    "        for _, (fc_, dropout) in enumerate(zip(self.fc_layers, self.dropout_layers)):\n",
    "            out = fc_(out)\n",
    "            out = self.activation[self.params[\"activation\"]](out)\n",
    "            out = dropout(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "\n",
    "    def process_dataset(self, dataset: DataSet, training: bool):\n",
    "        \"\"\"process the datasets for training and evaluation\n",
    "\n",
    "        This function transforms all the dataset into something that can be used by the neural network (for example)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : DataSet\n",
    "            A dataset that should be processed\n",
    "        training : bool, optional\n",
    "            indicate if we are in training phase or not, by default False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataLoader\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        if training:\n",
    "            self._infer_size(dataset)\n",
    "            batch_size = self.params[\"train_batch_size\"]\n",
    "            extract_x, extract_y = dataset.extract_data()\n",
    "            if self.scaler is not None:\n",
    "                extract_x, extract_y = self.scaler.fit_transform(extract_x, extract_y)\n",
    "        else:\n",
    "            batch_size = self.params[\"eval_batch_size\"]\n",
    "            extract_x, extract_y = dataset.extract_data()\n",
    "            if self.scaler is not None:\n",
    "                extract_x, extract_y = self.scaler.transform(extract_x, extract_y)\n",
    "\n",
    "        torch_dataset = TensorDataset(torch.from_numpy(extract_x).float(), torch.from_numpy(extract_y).float())\n",
    "        data_loader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=self.params[\"shuffle\"])\n",
    "        return data_loader\n",
    "\n",
    "    def _post_process(self, data):\n",
    "        \"\"\"\n",
    "        This function is used to inverse the predictions of the model to their original state, before scaling\n",
    "        to be able to compare them with ground truth data\n",
    "        \"\"\"\n",
    "        if self.scaler is not None:\n",
    "            try:\n",
    "                processed = self.scaler.inverse_transform(data)\n",
    "            except TypeError:\n",
    "                processed = self.scaler.inverse_transform(data.cpu())\n",
    "        else:\n",
    "            processed = data\n",
    "        return processed\n",
    "\n",
    "    def _infer_size(self, dataset: DataSet):\n",
    "        \"\"\"Infer the size of the input and ouput variables\n",
    "        \"\"\"\n",
    "        *dim_inputs, self.output_size = dataset.get_sizes()\n",
    "        self.input_size = np.sum(dim_inputs)\n",
    "\n",
    "    def get_metadata(self):\n",
    "        res_json = {}\n",
    "        res_json[\"input_size\"] = self.input_size\n",
    "        res_json[\"output_size\"] = self.output_size\n",
    "        return res_json\n",
    "\n",
    "    def _save_metadata(self, path: str):\n",
    "        res_json = {}\n",
    "        res_json[\"input_size\"] = self.input_size\n",
    "        res_json[\"output_size\"] = self.output_size\n",
    "        with open((path / \"metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(obj=res_json, fp=f, indent=4, sort_keys=True, cls=NpEncoder)\n",
    "\n",
    "    def _load_metadata(self, path: str):\n",
    "        if not isinstance(path, pathlib.Path):\n",
    "            path = pathlib.Path(path)\n",
    "        with open((path / \"metadata.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            res_json = json.load(fp=f)\n",
    "        self.input_size = res_json[\"input_size\"]\n",
    "        self.output_size = res_json[\"output_size\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
